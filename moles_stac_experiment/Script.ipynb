{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f06a64-ef21-4d59-b338-b1aa87bb5286",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyze of Moles DB fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c2ad0-a727-418f-bcd1-0e3458a2ac7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58d823b-d8ab-456a-b284-669864485430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "# loads json file to dictionary\n",
    "def json_to_dict(filename):\n",
    "    with gzip.open(filename, 'r') as f:\n",
    "        return json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "# saves dictionary to json file\n",
    "def dict_to_json(data, filename):\n",
    "    with gzip.open(filename, 'w') as f:\n",
    "        f.write(json.dumps(data).encode('utf-8'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f6ebd-8a96-4e8a-a88a-40f64d670a54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Flattening fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040fed69-a883-4e6d-a6ed-74cfc97682fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Refereanceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "200a2034-f74b-4fa2-a0ff-6f06101348a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns model's name\n",
    "def get_model_name(obj):\n",
    "    return obj['model'].split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1b20b56-56e3-446a-994a-b13adb5bea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps shortcode to model name\n",
    "\n",
    "map = {\n",
    "    'acq': 'acquisition',\n",
    "    'cmppr': 'compositeprocess',\n",
    "    'coll': 'observationcollection',\n",
    "    'comp': 'computation',\n",
    "    'instr': 'instrument',\n",
    "    'mpop': 'mobileplatformoperation',\n",
    "    'ob': 'observation',\n",
    "    'plat': 'platform',\n",
    "    'proj': 'project',\n",
    "    'result': 'result',\n",
    "    'excit': 'externalcitation',\n",
    "    }\n",
    "def map_shortcode_to_model_name(short_code, full=False):\n",
    "    if full:\n",
    "        return f'cedamoles_app.{map[short_code]}'\n",
    "    return map[short_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ca38a81-6086-4073-9653-e50b2fafc364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns dict of referenceable objects where keys are PKs and values are fields of those objects\n",
    "\n",
    "def get_referenceable_dict_from_list(ref_list):\n",
    "    output = dict()\n",
    "    for i in ref_list:\n",
    "        output[i['pk']] =  i['fields']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d8334282-93e7-4a0e-8098-a0725fc924d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inserts UUIDs into fields of corresponding models \n",
    "\n",
    "def include_referenceable(data):\n",
    "    output = []\n",
    "    referenceable = [i for i in data if i['model'] == 'cedamoles_app.referenceable']\n",
    "    referenceable = get_referenceable_dict_from_list(referenceable)\n",
    "    data = [i for i in data if i['model'] != 'cedamoles_app.referenceable']\n",
    "    \n",
    "    for i in data:\n",
    "        pk = i['pk']\n",
    "        if pk in referenceable and i['model'] == map_shortcode_to_model_name(referenceable[pk]['short_code'] , True):\n",
    "            my_obj = i\n",
    "            my_obj['fields']['uuid'] = referenceable[pk]['uuid']\n",
    "            output.append(my_obj)\n",
    "        else:\n",
    "            output.append(i)\n",
    "            \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6132075f-6a31-4727-a0d2-8e06663e5982",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inserting models into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7733306-79e5-4be9-aa28-e4fdec61f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. if observation has a filed phenomena which refers to the phenomena model by its PK, that model will be inserted into the observation\n",
    "\n",
    "def include_simple_field(data, model_name, model_and_field_pairs_to_insert_model):\n",
    "    values = {i['pk']: i['fields'] for i in data if i['model'] == f'cedamoles_app.{model_name}'}\n",
    "    data = [i for i in data if i['model'] != f'cedamoles_app.{model_name}']\n",
    "\n",
    "    for i in data:\n",
    "        for m, f in model_and_field_pairs_to_insert_model:\n",
    "            if i['model'] == f'cedamoles_app.{m}' and f in i['fields'] and i['fields'][f]:\n",
    "                if isinstance(i['fields'][f], list):\n",
    "                    i['fields'][f] = [values[j] for j in i['fields'][f]]\n",
    "                else:\n",
    "                    i['fields'][f] = values[i['fields'][f]]\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15d2b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. if relation between 2 models is done via foreign key (identifiers and observations) then fields from non-referenceable will be added to the referenceable\n",
    "\n",
    "def include_on_foreign_key(data, model_name, new_field_name=''):\n",
    "    output = []\n",
    "    ids = [i for i in data if i['model'] == f'cedamoles_app.{model_name}']\n",
    "    ids = {i['pk']: i['fields'] for i in ids}\n",
    "    data = [i for i in data if i['model'] != f'cedamoles_app.{model_name}']\n",
    "\n",
    "    for i in data:\n",
    "        if 'uuid' in i['fields'] and i['pk'] in ids:\n",
    "            fields = {k: v for k, v in ids[i['pk']].items() if k != 'relatedTo' and k !='ob_ref'}\n",
    "            i['fields'][new_field_name if new_field_name else model_name] = fields\n",
    "        \n",
    "        output.append(i)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f2f0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fields is unique \n",
    "\n",
    "def include_related_obs_info(data):\n",
    "    output = []\n",
    "    ids = [i for i in data if i['model'] == 'cedamoles_app.relatedobservationinfo']\n",
    "    ids = {i['fields']['objectObservation']: i['fields'] for i in ids}\n",
    "    data = [i for i in data if i['model'] != 'cedamoles_app.relatedobservationinfo']\n",
    "\n",
    "    for i in data:\n",
    "        if i['pk'] in ids:\n",
    "            fields = {k: v for k, v in ids[i['pk']].items() if k != 'objectObservation'}\n",
    "            i['fields']['relatedObservationInfo'] = fields\n",
    "        \n",
    "        output.append(i)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6132075f-6a31-4727-a0d2-8e06663e5982",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating relations and removing PKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cab7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps PK to UUID\n",
    "\n",
    "my_fixture = json_to_dict('fixture2.json.gz')\n",
    "my_map = {i['pk']: i['fields']['uuid'] for i in my_fixture}\n",
    "\n",
    "def map_pk_to_uuid(pk):\n",
    "    try:\n",
    "        return my_map[pk]\n",
    "    except KeyError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "188e0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces PHs with UUIDs\n",
    "\n",
    "list_of_fields = ['independentInstrument',\n",
    "                'mobilePlatformOperation',\n",
    "                'computationComponent',\n",
    "                'acquisitionComponent',\n",
    "                'subInstrument',\n",
    "                'platform_field',\n",
    "                'result_field',\n",
    "                'procedureAcquisition',\n",
    "                'procedureComputation',\n",
    "                'procedureCompositeProcess',\n",
    "                'projects',\n",
    "                'member',\n",
    "                'parentProject',\n",
    "                'observationCollection']\n",
    "\n",
    "def swap_pks_to_uuids(data):\n",
    "    output = []\n",
    "    for i in data:\n",
    "        if 'relatedObservationInfo' in i['fields']:\n",
    "            i['fields']['relatedObservationInfo']['subjectObservation'] = map_pk_to_uuid(i['fields']['relatedObservationInfo']['subjectObservation'])\n",
    "        \n",
    "        for f in list_of_fields:\n",
    "            if f in i['fields']:\n",
    "                if isinstance(i['fields'][f], list):\n",
    "                    i['fields'][f] = [map_pk_to_uuid(j) for j in i['fields'][f]]\n",
    "                else:\n",
    "                    i['fields'][f] = map_pk_to_uuid(i['fields'][f])\n",
    "        \n",
    "        output.append(i)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b3a1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange structure of records by removing PKs and bringing fields to the upper level\n",
    "\n",
    "def remove_pks(data):\n",
    "    output = []\n",
    "    for i in data:\n",
    "        model = i['model'].split('.')[1]\n",
    "        i = i['fields']\n",
    "        i['model'] = model\n",
    "        output.append(i)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e81dbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes specified field from dictionary recursively\n",
    "\n",
    "def remove_from_dict(data, field_path):\n",
    "    if data is None: \n",
    "        return\n",
    "        \n",
    "    field_path = field_path.split('/')\n",
    "\n",
    "    if field_path[0] not in data:\n",
    "        return data\n",
    "\n",
    "    if not field_path[1:]:\n",
    "        return {k: v for k, v in data.items() if k != field_path[0]}\n",
    "\n",
    "    data[field_path[0]] = remove_from_dict(data[field_path[0]], '/'.join(field_path[1:]))\n",
    "    \n",
    "    return data\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d79977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes specified field of one of the models from dictionary\n",
    "\n",
    "def remove_field_from_model(data, model_name, field_path):\n",
    "    output = []\n",
    " \n",
    "    for i in data:\n",
    "        try:\n",
    "            if i['model'] == model_name:\n",
    "                i = remove_from_dict(i, field_path)\n",
    "            output.append(i)\n",
    "        except:\n",
    "            print(f'Problem with path {field_path}. i = {i}')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d04a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes list of model-fieldpath pairs, removes them from the fixture and saves result to the new one\n",
    "\n",
    "def remove_fields_from_models_in_fixture(list_of_model_fieldpath_pairs, file_in = 'fixture3.json.gz', file_out = 'fixture4.json.gz'):\n",
    "    data = json_to_dict(file_in)\n",
    "    \n",
    "    for m, f in list_of_model_fieldpath_pairs:\n",
    "        data = remove_field_from_model(data, m, f)\n",
    "        \n",
    "\n",
    "    dict_to_json(data, file_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48c767",
   "metadata": {},
   "source": [
    "### Analyzing non empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f13869e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_not_nulls_helper(path, obj, out_dict):\n",
    "    if (obj != 0 and not obj) or obj is None:\n",
    "        out_dict[path] = out_dict.get(path, 0)\n",
    "        return\n",
    "    \n",
    "    out_dict[path] = out_dict.get(path, 0) + 1\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            count_not_nulls_helper(f'{path}/{k}', v, out_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "019f24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts how many non empty/non None values of certain field appeared in the database\n",
    "\n",
    "def count_not_nulls(grouped_data):\n",
    "    output = dict()\n",
    "\n",
    "    for m, l in grouped_data.items():\n",
    "        for f in l:\n",
    "            count_not_nulls_helper(m, f, output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32d8bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups records by model\n",
    "\n",
    "def group_by_model(data):\n",
    "    output = dict()\n",
    "    models = set([i['model'] for i in data])\n",
    "\n",
    "    for m in models:\n",
    "        output[m] = []\n",
    "    \n",
    "    for i in data:\n",
    "        output[i['model']].append(i)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "07b406ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves distribution of values to the txt file\n",
    "\n",
    "def save_distribution_to_the_file(data, filename='distribution.txt', group_by_count = False):\n",
    "    \n",
    "    dicted_data = group_by_model(data)\n",
    "    distribution = count_not_nulls(dicted_data)\n",
    "\n",
    "    if not group_by_count:\n",
    "        with open(filename, 'w') as f:\n",
    "            k1 = ''\n",
    "            for k, v in distribution.items():\n",
    "                model = k.split('/')[0]\n",
    "\n",
    "                if k1 != model:\n",
    "                    f.write('\\n')\n",
    "\n",
    "                k1 = model\n",
    "                f.write(f'{k}: {v}\\n')\n",
    "        return\n",
    "\n",
    "    \n",
    "    result = dict()\n",
    "\n",
    "    for k, v in distribution.items():\n",
    "        if v in result:\n",
    "            result[v].append(k)\n",
    "        else:\n",
    "            result[v] = [k]\n",
    "    \n",
    "    result = dict(sorted(result.items()))\n",
    "\n",
    "    filename = filename.split('.')[0]\n",
    "    with open(f'{filename}_grouped.txt', 'w') as f:\n",
    "        for k,v in result.items():\n",
    "            f.write(f'{k}:\\n')\n",
    "            for i in v:\n",
    "                f.write(f'\\t{i}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dabce",
   "metadata": {},
   "source": [
    "### Removing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f396661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes specified field from dictionary recursively\n",
    "\n",
    "def remove_from_dict(data, field_path):\n",
    "    if data is None: \n",
    "        return\n",
    "        \n",
    "    field_path = field_path.split('/')\n",
    "\n",
    "    if field_path[0] not in data:\n",
    "        return data\n",
    "\n",
    "    if not field_path[1:]:\n",
    "        return {k: v for k, v in data.items() if k != field_path[0]}\n",
    "\n",
    "    data[field_path[0]] = remove_from_dict(data[field_path[0]], '/'.join(field_path[1:]))\n",
    "    \n",
    "    return data\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98306d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes specified field of one of the models from dictionary\n",
    "\n",
    "def remove_field_from_model(data, model_name, field_path):\n",
    "    output = []\n",
    " \n",
    "    for i in data:\n",
    "        try:\n",
    "            if i['model'] == model_name:\n",
    "                i = remove_from_dict(i, field_path)\n",
    "            output.append(i)\n",
    "        except:\n",
    "            print(f'Problem with path {field_path}. i = {i}')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08b50742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes list of model-fieldpath pairs, removes them from the fixture and saves result to the new one\n",
    "\n",
    "def remove_fields_from_models_in_fixture(list_of_model_fieldpath_pairs, file_in = 'fixture3.json.gz', file_out = 'fixture4.json.gz'):\n",
    "    data = json_to_dict(file_in)\n",
    "    \n",
    "    for m, f in list_of_model_fieldpath_pairs:\n",
    "        data = remove_field_from_model(data, m, f)\n",
    "        \n",
    "\n",
    "    dict_to_json(data, file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95131df2",
   "metadata": {},
   "source": [
    "### Saving structure of fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7951a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress all the records under model to one record with non empty fields (if possible) which will be representative\n",
    "\n",
    "def compress_groups(data_by_model):\n",
    "    output = dict()\n",
    "    for m, l in data_by_model.items():\n",
    "        output[m] = dict()\n",
    "        for i in l:\n",
    "            for k, v in i.items():\n",
    "                if k not in output[m] or not output[m][k]:\n",
    "                    output[m][k] = v\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0510af60-e2f6-4f8b-b28e-e2ab6c83736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert values to the type name\n",
    "\n",
    "def convert_values_to_types(data):\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = convert_values_to_types(v)\n",
    "        return data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        if data:\n",
    "            return f'[{convert_values_to_types(data[0])}]'\n",
    "        return []\n",
    "\n",
    "    if isinstance(data, str) and len(data) == 32:\n",
    "        return 'uuid'\n",
    "\n",
    "    return data.__class__.__name__   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17b35ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary in the yaml like format to make it readible\n",
    "\n",
    "def save_formatted(obj, file, padding = ''):\n",
    "    if isinstance(obj, list):\n",
    "        for i in obj:\n",
    "            save_formatted(i, file, padding)\n",
    "\n",
    "        \n",
    "    elif isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            file.write(f'{padding}{k}:\\n')\n",
    "            save_formatted(v, file, padding + '\\t')\n",
    "            if not padding:\n",
    "                file.write('\\n')\n",
    "    \n",
    "    else:\n",
    "        file.write(f'{padding}{obj}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f453eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save structure of fixture to the file\n",
    "\n",
    "def save_structure(data, suffix=''):\n",
    "    data = group_by_model(data)\n",
    "    data = compress_groups(data)\n",
    "    data = {k: convert_values_to_types(v) for k,v in data.items()}\n",
    "    \n",
    "    with open(f'structure{suffix}.txt', 'w') as f:\n",
    "        save_formatted(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f800a2",
   "metadata": {},
   "source": [
    "## Main script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0c05c",
   "metadata": {},
   "source": [
    "### Fixture1.5 - tiding up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f0ac4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_to_dict('fixture.json.gz')\n",
    "data = [i for i in data if i['model'].split('.')[0] == 'cedamoles_app']\n",
    "dict_to_json(data, 'fixture1.5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ec823",
   "metadata": {},
   "source": [
    "### Fixture2 - flat fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a836329-7f92-464a-b58c-925644e5db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all the interation fixture is flatten down to the 10 refereanceable models and saved as fixture2.json\n",
    "\n",
    "data = json_to_dict('fixture1.5.json.gz')\n",
    "data = include_referenceable(data)\n",
    "data = include_simple_field(data, 'discoveryserviceid', [('observation', 'discoveryKeywords'), ('observationcollection', 'discoveryKeywords')])\n",
    "data = include_simple_field(data, 'dqconformanceresult', [('observation', 'resultQuality')])\n",
    "data = include_simple_field(data, 'constraints', [('imagedetails', 'imageConstraints'),('observation', 'permission')])\n",
    "data = include_simple_field(data, 'imagedetails', [('acquisition', 'imageDetails'), \n",
    "                                                  ('computation', 'imageDetails'),\n",
    "                                                  ('instrument', 'imageDetails'),\n",
    "                                                  ('observationcollection', 'imageDetails'),\n",
    "                                                  ('observation', 'imageDetails'),\n",
    "                                                  ('platform', 'imageDetails'),\n",
    "                                                  ('project', 'imageDetails'),\n",
    "                                                  ])\n",
    "data = include_simple_field(data, 'vocabularyterm', [('observation', 'vocabularyKeywords')])\n",
    "data = include_simple_field(data, 'verticalextent', [('observation', 'verticalExtent')])\n",
    "data = include_simple_field(data, 'timeperiod', [('mobileplatformoperation', 'operationTime'),\n",
    "                                                 ('observation', 'timePeriod'),\n",
    "                                                 ('observation', 'validTimePeriod')])\n",
    "data = include_simple_field(data, 'party', [('responsiblepartyinfo', 'party'),\n",
    "                                            ('review', 'commentator'),\n",
    "                                            ('review', 'reviewer')])\n",
    "data = include_simple_field(data, 'phenomenonname', [('phenomenon', 'names')])\n",
    "data = include_simple_field(data, 'phenomenonterm', [('phenomenon', 'terms')])\n",
    "data = include_simple_field(data, 'phenomenon', [('observation', 'phenomena')])\n",
    "data = include_simple_field(data, 'geographicboundingbox', [('mobileplatformoperation', 'location'),\n",
    "                                                            ('observation', 'geographicExtent'),\n",
    "                                                            ('platform', 'location')])\n",
    "\n",
    "data = include_on_foreign_key(data, 'drsdataset', 'drsDataset')\n",
    "data = include_on_foreign_key(data, 'identifier')\n",
    "data = include_on_foreign_key(data, 'onlineresource', 'onlineResource')\n",
    "data = include_on_foreign_key(data, 'migrationproperty', 'migrationProperty')\n",
    "data = include_on_foreign_key(data, 'note')\n",
    "data = include_on_foreign_key(data, 'responsiblepartyinfo', 'responsiblePartyInfo')\n",
    "data = include_on_foreign_key(data, 'review')\n",
    "\n",
    "data = include_on_foreign_key(data, 'inputoutputdescription', 'inputOutputDescription')\n",
    "data = include_on_foreign_key(data, 'instrumentplatformpair', 'instrumentPlatformPair')\n",
    "data = include_on_foreign_key(data, 'reviewnote', 'reviewNote')\n",
    "\n",
    "\n",
    "\n",
    "data = include_related_obs_info(data)\n",
    "\n",
    "dict_to_json(data, 'fixture2.json.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867624c6",
   "metadata": {},
   "source": [
    "### Fixture3 - relations via UUID; PKs removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baa32a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relations between models are established by UUIDs; PKs got removed; fixture saved as fixture3.json\n",
    "\n",
    "data = json_to_dict('fixture2.json.gz')\n",
    "data = swap_pks_to_uuids(data)\n",
    "data = remove_pks(data)\n",
    "dict_to_json(data, 'fixture3.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af4ecb",
   "metadata": {},
   "source": [
    "## Fixture3.5 - modifying geo extent to match the ES format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16cca06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_geo_extent(geo_extent):\n",
    "    if geo_extent is None:\n",
    "        return None\n",
    "        \n",
    "    output = {'type' : 'envelope',\n",
    "            'coordinates': []}\n",
    "    \n",
    "    output['coordinates'] = [\n",
    "        [geo_extent['westBoundLongitude'], \n",
    "        geo_extent['northBoundLatitude']], \n",
    "        [geo_extent['eastBoundLongitude'],\n",
    "        geo_extent['southBoundLatitude']]]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56b8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_to_dict('fixture3.json.gz')\n",
    "\n",
    "for x, i in enumerate(data):\n",
    "        if i['model'] == 'observation':\n",
    "            i['geographicExtent'] = modify_geo_extent(i['geographicExtent'])\n",
    "            data[x] = i\n",
    "        \n",
    "        if i['model'] in ['mobileplatformoperation', 'platform']:\n",
    "            if 'location' in i:\n",
    "                i['geographicExtent'] = modify_geo_extent(i['location'])\n",
    "                i = {k: v for k, v in i.items() if k != 'location'}\n",
    "                data[x] = i\n",
    "\n",
    "\n",
    "dict_to_json(data, 'fixture3.5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34014489",
   "metadata": {},
   "source": [
    "### Fixture4 - nulls removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbbbbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields which haven't been used across the entire DB are removed from it; fixture saved as fixture4.json\n",
    "\n",
    "data = json_to_dict('fixture3.json.gz')\n",
    "grouped_data = group_by_model(data)\n",
    "distribution = count_not_nulls(grouped_data)\n",
    "distribution = {k: v for k, v in distribution.items() if v == 0}\n",
    "\n",
    "fields_to_be_removed = []\n",
    "with open('empty_fields.txt', 'w') as f:\n",
    "    for i in distribution:\n",
    "        f.write(f'{i}\\n')\n",
    "        sep = i.find('/')\n",
    "        model = i[:sep]\n",
    "        path = i[sep + 1:]\n",
    "        fields_to_be_removed.append((model, path))\n",
    "\n",
    "fields_to_be_removed\n",
    "remove_fields_from_models_in_fixture(fields_to_be_removed, 'fixture3.json.gz', 'fixture4.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8b597e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_to_dict('fixture4.json.gz')\n",
    "save_structure(data, '_4')\n",
    "save_distribution_to_the_file(data, 'distribution_4.txt')\n",
    "save_distribution_to_the_file(data, 'distribution_4_grouped.txt', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ade929",
   "metadata": {},
   "source": [
    "### Fixture5 - irrelevant fields removed after the discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94feb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any fields specified in the fields_to_be_removed are be removed from the fixture and new fixture is saved as fixture5.json\n",
    "\n",
    "fields_to_be_removed = [\n",
    "    ('result', 'review'),\n",
    "]\n",
    "\n",
    "remove_fields_from_models_in_fixture(fields_to_be_removed, 'fixture4.json.gz', 'fixture5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ab752",
   "metadata": {},
   "source": [
    "## Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f58cb",
   "metadata": {},
   "source": [
    "### Analyzing sizes of fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df2891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(data):\n",
    "    if not isinstance(data, dict) and not isinstance(data, list):\n",
    "        return 0\n",
    "    \n",
    "    result = 0\n",
    "    if isinstance(data, list):\n",
    "        for i in data:\n",
    "            result += count_elements(i)\n",
    "        return result\n",
    "    \n",
    "    for k, v in data.items():\n",
    "        result += 1\n",
    "        result += count_elements(v)\n",
    "\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5c4bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def analyze_fixtures(filename):\n",
    "    suffixes = ['1.5', '2', '3', '4',]\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('name\\tsize[MB]\\tnumber_of_models\\tnumber_of_fields\\n')\n",
    "        for s in suffixes:\n",
    "            fname = f'fixture{s}.json.gz'\n",
    "            data = json_to_dict(fname)\n",
    "            fsize = Path(fname).stat().st_size / 1000000\n",
    "            num_of_models = len(data)\n",
    "            num_of_fields = count_elements(data)\n",
    "            f.write(f'{fname}\\t{fsize}\\t{num_of_models}\\t{num_of_fields}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d36a3",
   "metadata": {},
   "source": [
    "### Analyzing deepness of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bda710da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_analysis_of_deepness(filein, fileout):\n",
    "    data = json_to_dict(filein)\n",
    "    data = group_by_model(data)\n",
    "    data = count_not_nulls(data)   \n",
    "    \n",
    "    output = dict()\n",
    "    for k in data:\n",
    "        k1 = len(k.split('/')) - 1\n",
    "        if k1 in output:\n",
    "            output[k1].append(k)\n",
    "        else:\n",
    "            output[k1] = [k] \n",
    "    \n",
    "    with open(fileout, 'w') as f:\n",
    "        save_formatted(output, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc21af8",
   "metadata": {},
   "source": [
    "### Unzipping fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11dbff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_fixture(filename):\n",
    "    data = json_to_dict(filename)\n",
    "\n",
    "    newname = filename.split('.')\n",
    "    newname = \".\".join(newname[:-1])\n",
    "\n",
    "    with open(newname, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34590b8",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "96a2caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_datetime(value):\n",
    "    if not value or not isinstance(value, str):\n",
    "        return False\n",
    "  \n",
    "    try:\n",
    "        if value[4] == '-' and value[7] == '-' and value[10] == 'T':\n",
    "            return True\n",
    "    except IndexError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d5e0aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_fields(data, path=''):\n",
    "    output = dict()\n",
    "\n",
    "    if not data:\n",
    "        return output\n",
    "\n",
    "    if isinstance(data, str) and is_datetime(data):\n",
    "        output[path] = data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        output.update(get_date_fields(data[0], path))\n",
    "    \n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            output.update(get_date_fields(v, f'{path}/{k}'))\n",
    "    \n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb8870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e95ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting elasticsearch==7.13.1\n",
      "  Downloading elasticsearch-7.13.1-py2.py3-none-any.whl (354 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /Users/adrian.debski/Library/Python/3.10/lib/python/site-packages (from elasticsearch==7.13.1) (1.26.12)\n",
      "Requirement already satisfied: certifi in /Users/adrian.debski/Library/Python/3.10/lib/python/site-packages (from elasticsearch==7.13.1) (2022.9.24)\n",
      "Installing collected packages: elasticsearch\n",
      "  Attempting uninstall: elasticsearch\n",
      "    Found existing installation: elasticsearch 7.17.9\n",
      "    Uninstalling elasticsearch-7.17.9:\n",
      "      Successfully uninstalled elasticsearch-7.17.9\n",
      "Successfully installed elasticsearch-7.13.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install elasticsearch==7.13.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f27224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import yaml\n",
    "\n",
    "def get_config():\n",
    "    with open('fastapi.yml', encoding='utf-8') as reader:\n",
    "        conf = yaml.safe_load(reader)\n",
    "    \n",
    "    es_conf = conf.get(\"ELASTICSEARCH\")\n",
    "\n",
    "    return es_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd15f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, 'forbidden_response', 'forbidden')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstac-moles-test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/client/utils.py:168\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    167\u001b[0m         params[p] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(p)\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/client/__init__.py:406\u001b[0m, in \u001b[0;36mElasticsearch.index\u001b[0;34m(self, index, body, doc_type, id, params, headers)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mif\u001b[39;00m doc_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     doc_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_doc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 406\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    407\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mid\u001b[39;49m \u001b[39min\u001b[39;49;00m SKIP_IN_PATH \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    408\u001b[0m     _make_path(index, doc_type, \u001b[39mid\u001b[39;49m),\n\u001b[1;32m    409\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    410\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    411\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    412\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/transport.py:415\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    414\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    417\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39m# connection didn't fail, confirm it's live status\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection_pool\u001b[39m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/transport.py:381\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_connection()\n\u001b[1;32m    380\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     status, headers_response, data \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    382\u001b[0m         method,\n\u001b[1;32m    383\u001b[0m         url,\n\u001b[1;32m    384\u001b[0m         params,\n\u001b[1;32m    385\u001b[0m         body,\n\u001b[1;32m    386\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    387\u001b[0m         ignore\u001b[39m=\u001b[39;49mignore,\n\u001b[1;32m    388\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m \u001b[39mexcept\u001b[39;00m TransportError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/connection/http_urllib3.py:275\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m) \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore:\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_fail(\n\u001b[1;32m    273\u001b[0m         method, full_url, url, orig_body, duration, response\u001b[39m.\u001b[39mstatus, raw_data\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error(response\u001b[39m.\u001b[39;49mstatus, raw_data)\n\u001b[1;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_request_success(\n\u001b[1;32m    278\u001b[0m     method, full_url, url, orig_body, response\u001b[39m.\u001b[39mstatus, raw_data, duration\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mstatus, response\u001b[39m.\u001b[39mgetheaders(), raw_data\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/elasticsearch/connection/base.py:330\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    328\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mUndecodable raw error response from server: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, err)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    331\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    332\u001b[0m )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, 'forbidden_response', 'forbidden')"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "es_conf = get_config()\n",
    "es_kwargs = es_conf.get(\"SESSION_KWARGS\")\n",
    "\n",
    "es = Elasticsearch(**es_kwargs)\n",
    "\n",
    "with open('fixture3.5.json') as f:\n",
    "    data = json.load(f)\n",
    "    for i in data:\n",
    "        es.index(index='stac-moles-test', body=i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5be5799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': 'J. Tennyson, M.A. Kostin, P. Barletta, G.J. Harris, O.L. Polyansky, J. Ramanlal and N.F. Zobov',\n",
       " 'title': 'DVR3D: a program suite for the calculation of rotation-vibration spectra of triatomic molecules',\n",
       " 'date': '2004-11-01T00:00:00Z',\n",
       " 'publicationType': 'article',\n",
       " 'collectiveTitle': 'Computer Phys. Comm, 163',\n",
       " 'edition': '163',\n",
       " 'pageNumbers': '85-116',\n",
       " 'otherCitationDetails': None,\n",
       " 'uuid': '9a241b172c3b4505b8e173504d76e33f',\n",
       " 'drsDataset': {'drsId': 'cmip5.output1.MIROC.MIROC5.decadal1998.mon.ocean.Omon.r3i1p1.v20131009',\n",
       "  'version': 'v20131009',\n",
       "  'directory': '/badc/cmip5/data/cmip5/output1/MIROC/MIROC5/decadal1998/mon/ocean/Omon/r3i1p1/v20131009'},\n",
       " 'onlineResource': {'applicationProfile': None,\n",
       "  'function': 'documentation',\n",
       "  'internalResourceType': None,\n",
       "  'linkage': 'https://doi.org/10.5194/amt-2018-302',\n",
       "  'name': 'Pickering, B. S., Neely III, R. R., & Harrison, D. (2018). The Disdrometer Verification Network (DiVeN): a UK network of laser precipitation instruments. Atmospheric Measurement Techniques Discussions, 2018, 1-34.',\n",
       "  'description': None},\n",
       " 'model': 'externalcitation'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_to_dict('fixture3.5.json.gz')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43e392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
